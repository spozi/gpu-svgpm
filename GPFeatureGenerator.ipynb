{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPFeatureGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqlmwWqivUrPRc4KSjpKuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spozi/gpu-svgpm/blob/main/GPFeatureGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ZEI1ZknHnT",
        "outputId": "21dcba1d-4e61-4dc4-e0b0-cde13408fddd"
      },
      "source": [
        "!pip install -U deap imbalanced-learn scikit-learn-intelex"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: scikit-learn-intelex in /usr/local/lib/python3.7/dist-packages (2021.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (2.2.0)\n",
            "Requirement already satisfied: daal4py==2021.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (2021.3.0)\n",
            "Requirement already satisfied: daal==2021.3.0 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.3.0->scikit-learn-intelex) (2021.3.0)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from daal==2021.3.0->daal4py==2021.3.0->scikit-learn-intelex) (2021.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irgcpLpFBF-3",
        "outputId": "4ff0505c-a68f-4b1a-d9de-e51f6b3b4489"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import site\n",
        "sys.path.append(os.path.join(os.path.dirname(site.getsitepackages()[0]), \"site-packages\"))\n",
        "\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASNSiD1zsUJ8"
      },
      "source": [
        "#@title SVGPM Configuration\n",
        "#@markdown ---\n",
        "#@markdown ### Enter a file path:\n",
        "train_file_path = \"/content/Earthquakes_train.csv\" #@param {type:\"string\"}\n",
        "test_file_path = \"/content/Earthquakes_test.csv\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Enter SVGPM Parameters:\n",
        "population_size = 500 #@param {type:\"slider\", min:0, max:1000, step:2}\n",
        "number_of_generation = 250 #@param {type:\"slider\", min:0, max:1000, step:2}\n",
        "\n",
        "#@markdown ### Enter 2^C and 2^Gamma Parameter:\n",
        "C = -2 #@param {type:\"slider\", min:-10, max:10, step:1}\n",
        "gamma = -3 #@param {type:\"slider\", min:-10, max:10, step:1}\n",
        "#@markdown ---"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjaiCtAhnPHP"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#Train and test file\n",
        "train_file = train_file_path\n",
        "test_file = test_file_path\n",
        "\n",
        "train_data = np.loadtxt(train_file, delimiter=\",\", skiprows=1)\n",
        "test_data = np.loadtxt(test_file, delimiter=\",\", skiprows=1)\n",
        "\n",
        "X_train = train_data[:, 1:]\n",
        "X_test = test_data[:, 1:]\n",
        "\n",
        "#Scale each feature to 0 and 1\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#y_train\n",
        "y_train = train_data[:, 0].astype(int)\n",
        "y_test = test_data[:, 0].astype(int)\n",
        "\n",
        "#Compute class weight\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "pos_index = 0\n",
        "neg_index = 0\n",
        "if counts[0] < counts[1]:\n",
        "  pos_index = 0\n",
        "  neg_index = 1\n",
        "else:\n",
        "  pos_index = 1\n",
        "  neg_index = 0\n",
        "\n",
        "class_weight = {pos_index: counts[neg_index], neg_index: counts[pos_index]}\n",
        "# if pos_index == 0:\n",
        "#   class_weight = {pos_index: counts[neg_index]} #Total of negative class: Total of positive class\n",
        "# elif pos_index == 1:\n",
        "#   class_weight = {pos_index: counts[neg_index]}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n4G13-SRMp2"
      },
      "source": [
        "Version 2 GP Feature Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UpoPcmQMMda"
      },
      "source": [
        "import random\n",
        "import operator\n",
        "import math\n",
        "import statistics\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from deap import algorithms\n",
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "from deap import gp\n",
        "\n",
        "# Define new functions\n",
        "def protectedDiv(left, right):\n",
        "    try:\n",
        "        return left / right\n",
        "    except ZeroDivisionError:\n",
        "        return 1\n",
        "\n",
        "nFeatures = X_train.data.shape[1]\n",
        "pset = gp.PrimitiveSet(\"MAIN\", nFeatures) \n",
        "pset.addPrimitive(operator.add, 2)\n",
        "pset.addPrimitive(operator.sub, 2)\n",
        "pset.addPrimitive(operator.mul, 2)\n",
        "pset.addPrimitive(protectedDiv, 2)\n",
        "pset.addPrimitive(operator.neg, 1)\n",
        "pset.addPrimitive(math.erfc, 1)\n",
        "pset.addPrimitive(math.erf, 1)\n",
        "pset.addPrimitive(math.exp, 1)\n",
        "pset.addPrimitive(math.gamma, 1)\n",
        "pset.addPrimitive(math.sqrt, 1)\n",
        "pset.addPrimitive(math.cos, 1)\n",
        "pset.addPrimitive(math.sin, 1)\n",
        "pset.addEphemeralConstant(\"rand1\", lambda: round(random.uniform(0.1, 1.0), 10))\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, 0.8))\n",
        "creator.create(\"Tree\", gp.PrimitiveTree)\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"main_expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=5)\n",
        "toolbox.register('MAIN', tools.initIterate, creator.Tree, toolbox.main_expr)\n",
        "\n",
        "func_cycle = [toolbox.MAIN]\n",
        "\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual, func_cycle)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71GGjz4mQ9SS"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from time import time\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def evalSymbReg(score):\n",
        "  return (score[0], score[1])\n",
        "\n",
        "def evalSymbRegPop(population):\n",
        "  # Evaluate each individual in population\n",
        "  #1. Compute the expression of every individual\n",
        "  list_vecs = []\n",
        "  # start = time()\n",
        "  for individual in population:\n",
        "    #The following code should be optimized/vectorized\n",
        "    #Evaluating expression on each vector\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    vec = []\n",
        "    for x in X_train: #Iterate every vector x (row) in data (matrix) X\n",
        "      try:\n",
        "        val = func(*x)\n",
        "        vec.append(val)\n",
        "      except:\n",
        "        vec.append(0)\n",
        "    list_vecs.append(vec)\n",
        "  end = time()\n",
        "  # expression_evaluation_time = end - start\n",
        "\n",
        "  #2. Convert list_vecs to numpy array\n",
        "  evaluated_X = np.array(list_vecs).T\n",
        "  evaluated_X = np.float32(evaluated_X)\n",
        "  evaluated_X = np.nan_to_num(evaluated_X, copy=True, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "  evaluated_X_train = np.hstack((X_train, evaluated_X)) #Merge x_train with evaluated_x\n",
        "\n",
        "  #3. Individual (feature) selection\n",
        "  # https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection-using-selectfrommodel\n",
        "\n",
        "  # start = time()\n",
        "  clf = ExtraTreesClassifier(n_estimators=50)\n",
        "  clf = clf.fit(evaluated_X_train, y_train)\n",
        "\n",
        "  #4. Extract features that at top threshold (get the 50 percentile)\n",
        "  q1 = np.percentile(clf.feature_importances_, 50)                                        #Get the top 50 percentile features\n",
        "  features = [True if val >= q1 else False for val in clf.feature_importances_.tolist()]  #Get the features indices\n",
        "  features = features[X_train.shape[1]:]                                                  #Extract GP Features from all features\n",
        "  X_train_new = evaluated_X[:, features]                                                  #Form a new training data with GP Features\n",
        "  # end = time()\n",
        "  # feature_evaluation_time = end - start\n",
        "\n",
        "  #5. Merge X_train with X_train_new row-wise\n",
        "  X_train_new = np.hstack((X_train, X_train_new))                                         #Merge back original training data with new GP based training data\n",
        "\n",
        "  #6. Use svc to get total nSV\n",
        "  # start = time()\n",
        "  clf_svc = SVC(C=2**C, gamma=2**gamma, class_weight=class_weight)      #Based on original paper \n",
        "  # clf_svc = SVC(C=1, kernel='linear')                                 #Smaller C value will increase the margin size of the hyperplane. The new features should be generate such that it has very high linear seperability\n",
        "  clf_svc.fit(X_train_new, y_train)                                     #98% of runtime is at here\n",
        "  # end = time()\n",
        "  # svm_training_time = end - start\n",
        "\n",
        "  # print(\"Expression evaluation: %.4f, Feature evaluation: %.4f, SVM training: %.4f\" % (expression_evaluation_time, feature_evaluation_time, svm_training_time))\n",
        "\n",
        "  y_pred = clf_svc.predict(X_train_new)\n",
        "\n",
        "  #7. Compute the score\n",
        "  nSV = clf_svc.support_vectors_.shape[0]\n",
        "  tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
        "  f1 = f1_score(y_train, y_pred)\n",
        "  accuracy = accuracy_score(y_train, y_pred)\n",
        "  specificity = tp / (tp + fn)\n",
        "  sensititivy = tn / (tn + fp)\n",
        "  gmean = math.sqrt(specificity * sensititivy)\n",
        "  # print(gmean,accuracy,min(gmean,accuracy)/nSV)\n",
        "  fitness = (min(gmean,accuracy), min(gmean,accuracy)/nSV)\n",
        "\n",
        "  #8. Output the fitness value\n",
        "  ind_pop_fitness = []\n",
        "  for f in features:\n",
        "    if f is True:\n",
        "      ind_pop_fitness.append(fitness) #If the feature is in the tree, set the fitness value to fitness\n",
        "    else:\n",
        "      ind_pop_fitness.append((0,0))     #If the feature is in the tree, set the fitness value to 0\n",
        "  \n",
        "  return ind_pop_fitness\n",
        "\n",
        "psets = [pset]\n",
        "toolbox.register(\"compile\", gp.compileADF, psets=psets)\n",
        "toolbox.register('evaluate', evalSymbReg)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)\n",
        "toolbox.register('mate', gp.cxOnePoint)\n",
        "toolbox.register(\"expr\", gp.genFull, min_=1, max_=2)\n",
        "toolbox.register('mutate', gp.mutUniform, expr=toolbox.expr)\n",
        "\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=80))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=80))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_7HXCBEMQmU",
        "outputId": "07fb9025-9413-4a5b-ad75-ea71ac548e48"
      },
      "source": [
        "def main():\n",
        "  random.seed(1024)\n",
        "  ind = toolbox.individual()\n",
        "  \n",
        "  pop = toolbox.population(n=population_size)\n",
        "  hof = tools.HallOfFame(population_size)\n",
        "  stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "  stats.register(\"avg\", np.mean)\n",
        "  stats.register(\"std\", np.std)\n",
        "  stats.register(\"min\", np.min)\n",
        "  stats.register(\"max\", np.max)\n",
        "\n",
        "  logbook = tools.Logbook()\n",
        "  logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
        "\n",
        "  CXPB, MUTPB, NGEN = 0.5, 0.2, number_of_generation\n",
        "\n",
        "  # # Evaluate the entire population\n",
        "  #1. Compute the metric on the set of individuals\n",
        "  ind_pop_fitness = evalSymbRegPop(pop)\n",
        "\n",
        "  #2. Then, determine the best individual using toolbox\n",
        "  for ind, fitness in zip(pop, ind_pop_fitness):\n",
        "    ind.fitness.values = toolbox.evaluate(fitness)\n",
        "\n",
        "  hof.update(pop)\n",
        "  record = stats.compile(pop)\n",
        "  logbook.record(gen=0, evals=len(pop), **record)\n",
        "  print(logbook.stream)\n",
        "\n",
        "  for g in range(1, NGEN):\n",
        "    # Select the offspring\n",
        "    offspring = toolbox.select(pop, len(pop))\n",
        "    # Clone the offspring\n",
        "    offspring = [toolbox.clone(ind) for ind in offspring]\n",
        "\n",
        "    # Apply crossover and mutation\n",
        "    for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
        "        for tree1, tree2 in zip(ind1, ind2):\n",
        "            if random.random() < CXPB:\n",
        "                toolbox.mate(tree1, tree2)\n",
        "                del ind1.fitness.values\n",
        "                del ind2.fitness.values\n",
        "\n",
        "    for ind in offspring:\n",
        "        for tree, pset in zip(ind, psets):\n",
        "            if random.random() < MUTPB:\n",
        "                toolbox.mutate(individual=tree, pset=pset)\n",
        "                del ind.fitness.values\n",
        "                        \n",
        "    # Evaluate the individuals with an invalid fitness\n",
        "    invalids = [ind for ind in offspring if not ind.fitness.valid]\n",
        "\n",
        "    #1. Compute the metric on the set of individuals\n",
        "    ind_pop_invalid_fitness = evalSymbRegPop(invalids)\n",
        "\n",
        "    #2. Then, determine the best individual using toolbox\n",
        "    for ind, fitness in zip(invalids, ind_pop_invalid_fitness):\n",
        "      ind.fitness.values = toolbox.evaluate(fitness)\n",
        "            \n",
        "    # Replacement of the population by the offspring\n",
        "    pop = offspring\n",
        "    hof.update(pop)\n",
        "    record = stats.compile(pop)\n",
        "    logbook.record(gen=g, evals=len(invalids), **record)\n",
        "    print(logbook.stream)\n",
        "  \n",
        "  print('Best individual : ', hof[0][0], hof[0].fitness)\n",
        "  return pop, stats, hof\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pop, stats, hof = main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9737945687202026 0.9906832298136646 0.0030526475508470302\n",
            "gen\tevals\tstd     \tmin\tavg     \tmax     \n",
            "0  \t500  \t0.418392\t0  \t0.239328\t0.973795\n",
            "0.9866533578135983 0.9782608695652174 0.003038077234674588\n",
            "1  \t286  \t0.46049 \t0  \t0.329852\t0.978261\n",
            "1.0 1.0 0.003105590062111801\n",
            "2  \t301  \t0.468126\t0  \t0.340565\t1       \n",
            "0.9559252603882146 0.984472049689441 0.002977960312735871\n",
            "3  \t307  \t0.464338\t0  \t0.340741\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003080273883639608\n",
            "4  \t281  \t0.472854\t0  \t0.35942 \t1       \n",
            "0.982607368881035 0.9937888198757764 0.003099707788268249\n",
            "5  \t272  \t0.474377\t0  \t0.359053\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0038188022302753045\n",
            "6  \t306  \t0.461608\t0  \t0.323384\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "7  \t291  \t0.467121\t0  \t0.329379\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "8  \t308  \t0.473816\t0  \t0.350126\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "9  \t322  \t0.470367\t0  \t0.335409\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "10 \t290  \t0.474526\t0  \t0.350642\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0030431080272506333\n",
            "11 \t303  \t0.47092 \t0  \t0.349477\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "12 \t290  \t0.478662\t0  \t0.363873\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "13 \t337  \t0.469754\t0  \t0.331958\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "14 \t298  \t0.47829 \t0  \t0.358109\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "15 \t334  \t0.47194 \t0  \t0.338047\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030979432136778126\n",
            "16 \t286  \t0.479583\t0  \t0.367756\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "17 \t289  \t0.474327\t0  \t0.350493\t1       \n",
            "0.9559252603882146 0.984472049689441 0.0030443479630197917\n",
            "18 \t312  \t0.467665\t0  \t0.350812\t1       \n",
            "0.9468641529479986 0.9813664596273292 0.0030154909329554096\n",
            "19 \t330  \t0.461467\t0  \t0.342355\t1       \n",
            "0.9913418283769 0.9968944099378882 0.004329003617366376\n",
            "20 \t311  \t0.472639\t0  \t0.358008\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "21 \t294  \t0.479322\t0  \t0.366902\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003127261288255205\n",
            "22 \t308  \t0.474392\t0  \t0.350577\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "23 \t328  \t0.46943 \t0  \t0.34155 \t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "24 \t286  \t0.474372\t0  \t0.35829 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "25 \t291  \t0.47897 \t0  \t0.364912\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "26 \t303  \t0.477932\t0  \t0.357841\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "27 \t308  \t0.478805\t0  \t0.360064\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "28 \t292  \t0.479658\t0  \t0.374167\t1       \n",
            "1.0 1.0 0.014925373134328358\n",
            "29 \t285  \t0.480028\t0  \t0.374291\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "30 \t291  \t0.478626\t0  \t0.376809\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "31 \t309  \t0.478146\t0  \t0.365012\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "32 \t299  \t0.482364\t0  \t0.378299\t1       \n",
            "1.0 1.0 0.003115264797507788\n",
            "33 \t303  \t0.479937\t0  \t0.368356\t1       \n",
            "0.9468641529479986 0.9813664596273292 0.0029869531638738126\n",
            "34 \t314  \t0.466308\t0  \t0.353641\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "35 \t290  \t0.477883\t0  \t0.369569\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "36 \t316  \t0.472979\t0  \t0.350124\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "37 \t287  \t0.479726\t0  \t0.368744\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.009363409314617334\n",
            "38 \t318  \t0.469248\t0  \t0.351495\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "39 \t302  \t0.479163\t0  \t0.370271\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0030431080272506333\n",
            "40 \t296  \t0.475027\t0  \t0.366685\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0030526475508470302\n",
            "41 \t290  \t0.47484 \t0  \t0.368848\t1       \n",
            "0.9923953268977463 0.9875776397515528 0.0030670113035762506\n",
            "42 \t314  \t0.474789\t0  \t0.361732\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "43 \t322  \t0.477554\t0  \t0.362246\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "44 \t281  \t0.48002 \t0  \t0.380255\t1       \n",
            "0.9559252603882146 0.984472049689441 0.002968711988783275\n",
            "45 \t287  \t0.471069\t0  \t0.36361 \t1       \n",
            "0.9559252603882146 0.984472049689441 0.002977960312735871\n",
            "46 \t321  \t0.464683\t0  \t0.3491  \t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "47 \t294  \t0.47447 \t0  \t0.36302 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "48 \t284  \t0.480236\t0  \t0.373375\t1       \n",
            "1.0 1.0 0.003115264797507788\n",
            "49 \t314  \t0.476947\t0  \t0.35804 \t1       \n",
            "0.9468641529479986 0.9813664596273292 0.002968226184789964\n",
            "50 \t325  \t0.464736\t0  \t0.34912 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "51 \t269  \t0.479526\t0  \t0.377019\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "52 \t298  \t0.473822\t0  \t0.353009\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "53 \t302  \t0.476171\t0  \t0.355677\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "54 \t298  \t0.476718\t0  \t0.356033\t1       \n",
            "0.9672673160021797 0.9472049689440993 0.0029600155279503105\n",
            "55 \t295  \t0.467569\t0  \t0.354609\t1       \n",
            "1.0 1.0 0.003125\n",
            "56 \t283  \t0.477172\t0  \t0.363801\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "57 \t311  \t0.472554\t0  \t0.3533  \t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "58 \t290  \t0.472677\t0  \t0.355664\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "59 \t306  \t0.472247\t0  \t0.34976 \t1       \n",
            "0.9559252603882146 0.984472049689441 0.0029872664387131705\n",
            "60 \t297  \t0.469884\t0  \t0.36195 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "61 \t290  \t0.472521\t0  \t0.350208\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030979432136778126\n",
            "62 \t292  \t0.475906\t0  \t0.359845\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "63 \t329  \t0.472066\t0  \t0.342533\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "64 \t305  \t0.475932\t0  \t0.353982\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "65 \t309  \t0.475281\t0  \t0.356625\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "66 \t317  \t0.477074\t0  \t0.358769\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "67 \t294  \t0.478259\t0  \t0.362201\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "68 \t283  \t0.48176 \t0  \t0.375411\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0030431080272506333\n",
            "69 \t314  \t0.468462\t0  \t0.343703\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "70 \t294  \t0.472562\t0  \t0.346883\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "71 \t281  \t0.480476\t0  \t0.371153\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "72 \t314  \t0.475986\t0  \t0.354204\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003070648027753234\n",
            "73 \t299  \t0.47089 \t0  \t0.346575\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "74 \t268  \t0.476556\t0  \t0.368254\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "75 \t318  \t0.468375\t0  \t0.333257\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "76 \t305  \t0.475697\t0  \t0.353031\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0030816283820259576\n",
            "77 \t302  \t0.473163\t0  \t0.359573\t1       \n",
            "0.9377154924749757 0.9782608695652174 0.0029580930361986614\n",
            "78 \t301  \t0.460872\t0  \t0.341821\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "79 \t317  \t0.470855\t0  \t0.34627 \t1       \n",
            "0.9731236802019038 0.9565217391304348 0.003017418735427239\n",
            "80 \t345  \t0.459598\t0  \t0.329437\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "81 \t312  \t0.474006\t0  \t0.355188\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "82 \t287  \t0.480123\t0  \t0.369477\t1       \n",
            "0.9559252603882146 0.984472049689441 0.002977960312735871\n",
            "83 \t296  \t0.470266\t0  \t0.359586\t1       \n",
            "0.982607368881035 0.9937888198757764 0.00308996027950011\n",
            "84 \t323  \t0.468406\t0  \t0.344228\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "85 \t296  \t0.47335 \t0  \t0.349447\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.003024206735155909\n",
            "86 \t288  \t0.473345\t0  \t0.359862\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "87 \t302  \t0.478326\t0  \t0.366256\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "88 \t273  \t0.476489\t0  \t0.365756\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.0030247689070658787\n",
            "89 \t300  \t0.474422\t0  \t0.373427\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "90 \t310  \t0.473597\t0  \t0.351703\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "91 \t291  \t0.475063\t0  \t0.362266\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "92 \t282  \t0.478732\t0  \t0.378905\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "93 \t310  \t0.473924\t0  \t0.350728\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "94 \t307  \t0.477209\t0  \t0.359439\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "95 \t305  \t0.47578 \t0  \t0.354488\t1       \n",
            "0.9468641529479986 0.9813664596273292 0.0029589504779624957\n",
            "96 \t307  \t0.459761\t0  \t0.329455\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "97 \t281  \t0.472159\t0  \t0.358232\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "98 \t317  \t0.471092\t0  \t0.345671\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0030914113292704846\n",
            "99 \t308  \t0.471812\t0  \t0.357747\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "100\t275  \t0.473793\t0  \t0.356284\t1       \n",
            "0.9559252603882146 0.984472049689441 0.002977960312735871\n",
            "101\t306  \t0.466035\t0  \t0.348899\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "102\t289  \t0.471055\t0  \t0.346472\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "103\t304  \t0.471735\t0  \t0.350867\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "104\t287  \t0.479111\t0  \t0.367603\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "105\t304  \t0.4771  \t0  \t0.358135\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "106\t319  \t0.473631\t0  \t0.345967\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "107\t286  \t0.47884 \t0  \t0.368819\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "108\t302  \t0.47261 \t0  \t0.348454\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "109\t311  \t0.478179\t0  \t0.362706\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003070648027753234\n",
            "110\t301  \t0.474201\t0  \t0.358181\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.002996587830291973\n",
            "111\t278  \t0.475683\t0  \t0.376771\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "112\t262  \t0.479551\t0  \t0.374612\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "113\t286  \t0.480833\t0  \t0.379609\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "114\t300  \t0.475685\t0  \t0.354829\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "115\t312  \t0.475295\t0  \t0.352158\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "116\t327  \t0.472813\t0  \t0.354875\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "117\t297  \t0.475559\t0  \t0.355937\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "118\t304  \t0.475573\t0  \t0.357513\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "119\t299  \t0.477243\t0  \t0.359624\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.002996587830291973\n",
            "120\t320  \t0.467879\t0  \t0.347934\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.01232651352810383\n",
            "121\t322  \t0.465114\t0  \t0.344396\t1       \n",
            "0.9750679851977377 0.9596273291925466 0.0029894932373599583\n",
            "122\t310  \t0.46441 \t0  \t0.347675\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "123\t296  \t0.470221\t0  \t0.35157 \t1       \n",
            "0.9737945687202026 0.9906832298136646 0.003033627939938326\n",
            "124\t310  \t0.467034\t0  \t0.342886\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "125\t291  \t0.476797\t0  \t0.363073\t1       \n",
            "0.9574271077563381 0.9316770186335404 0.0029298019453884916\n",
            "126\t304  \t0.463087\t0  \t0.350192\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "127\t322  \t0.468929\t0  \t0.339395\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "128\t270  \t0.476732\t0  \t0.357937\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.003015316504231298\n",
            "129\t306  \t0.467651\t0  \t0.346256\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "130\t281  \t0.476685\t0  \t0.361615\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.003015316504231298\n",
            "131\t284  \t0.47519 \t0  \t0.372426\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "132\t315  \t0.47594 \t0  \t0.357172\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "133\t289  \t0.475827\t0  \t0.358721\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "134\t309  \t0.473428\t0  \t0.346441\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "135\t288  \t0.480229\t0  \t0.36787 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "136\t297  \t0.474227\t0  \t0.348011\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "137\t280  \t0.4792  \t0  \t0.365227\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "138\t309  \t0.473396\t0  \t0.346298\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "139\t280  \t0.477097\t0  \t0.358335\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "140\t298  \t0.47214 \t0  \t0.347093\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.0030431080272506333\n",
            "141\t326  \t0.46251 \t0  \t0.32851 \t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "142\t293  \t0.476875\t0  \t0.368353\t1       \n",
            "0.9789450103725609 0.9658385093167702 0.0029994984761390377\n",
            "143\t337  \t0.461754\t0  \t0.331379\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "144\t281  \t0.473016\t0  \t0.352661\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "145\t292  \t0.477077\t0  \t0.358878\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "146\t310  \t0.472789\t0  \t0.344179\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "147\t293  \t0.473793\t0  \t0.347194\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "148\t289  \t0.478014\t0  \t0.361285\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "149\t312  \t0.470267\t0  \t0.335959\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "150\t312  \t0.474955\t0  \t0.349908\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "151\t284  \t0.476991\t0  \t0.357072\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "152\t317  \t0.470275\t0  \t0.335947\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "153\t298  \t0.473928\t0  \t0.347005\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "154\t312  \t0.470956\t0  \t0.337965\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "155\t316  \t0.475501\t0  \t0.352021\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "156\t327  \t0.469594\t0  \t0.333918\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "157\t316  \t0.473023\t0  \t0.343901\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "158\t290  \t0.475895\t0  \t0.352906\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "159\t310  \t0.477103\t0  \t0.356918\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "160\t279  \t0.479592\t0  \t0.366076\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "161\t292  \t0.478218\t0  \t0.366793\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "162\t306  \t0.469016\t0  \t0.333647\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "163\t312  \t0.47015 \t0  \t0.33584 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "164\t303  \t0.471619\t0  \t0.339942\t1       \n",
            "0.9559252603882146 0.984472049689441 0.0030155370990164495\n",
            "165\t310  \t0.465191\t0  \t0.34343 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "166\t302  \t0.47313 \t0  \t0.350877\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.003024206735155909\n",
            "167\t311  \t0.47296 \t0  \t0.360052\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "168\t264  \t0.476126\t0  \t0.358949\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "169\t291  \t0.477716\t0  \t0.36089 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "170\t285  \t0.475226\t0  \t0.352178\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "171\t315  \t0.4737  \t0  \t0.347324\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "172\t319  \t0.472847\t0  \t0.34415 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "173\t288  \t0.475064\t0  \t0.351195\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "174\t306  \t0.471116\t0  \t0.342658\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "175\t291  \t0.476819\t0  \t0.357613\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "176\t290  \t0.479417\t0  \t0.366072\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "177\t280  \t0.481886\t0  \t0.375246\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "178\t314  \t0.473919\t0  \t0.347017\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "179\t309  \t0.474896\t0  \t0.349991\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "180\t319  \t0.467855\t0  \t0.328831\t1       \n",
            "0.9737945687202026 0.9906832298136646 0.003024206735155909\n",
            "181\t296  \t0.471017\t0  \t0.35092 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "182\t320  \t0.472308\t0  \t0.34408 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "183\t333  \t0.468634\t0  \t0.330596\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "184\t316  \t0.475445\t0  \t0.350589\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "185\t278  \t0.479648\t0  \t0.364624\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.003005922994872322\n",
            "186\t291  \t0.473163\t0  \t0.362072\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "187\t305  \t0.476897\t0  \t0.360313\t1       \n",
            "1.0 1.0 0.003115264797507788\n",
            "188\t299  \t0.479146\t0  \t0.364627\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "189\t313  \t0.474707\t0  \t0.348811\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "190\t279  \t0.478205\t0  \t0.361026\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "191\t297  \t0.471122\t0  \t0.346401\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "192\t293  \t0.474244\t0  \t0.349933\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.002996587830291973\n",
            "193\t285  \t0.473371\t0  \t0.363423\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "194\t303  \t0.473273\t0  \t0.348789\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "195\t285  \t0.475249\t0  \t0.351922\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "196\t284  \t0.480386\t0  \t0.369121\t1       \n",
            "1.0 1.0 0.0038910505836575876\n",
            "197\t285  \t0.47791 \t0  \t0.361425\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "198\t290  \t0.470667\t0  \t0.338377\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "199\t294  \t0.473931\t0  \t0.34845 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "200\t299  \t0.473697\t0  \t0.347329\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "201\t286  \t0.474763\t0  \t0.355094\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "202\t302  \t0.470708\t0  \t0.338954\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "203\t302  \t0.47431 \t0  \t0.34914 \t1       \n",
            "0.9711754826918862 0.953416149068323 0.0029609197176034873\n",
            "204\t316  \t0.457504\t0  \t0.320861\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "205\t304  \t0.465049\t0  \t0.331459\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "206\t278  \t0.477844\t0  \t0.364199\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "207\t289  \t0.471931\t0  \t0.345905\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "208\t301  \t0.475357\t0  \t0.353809\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "209\t302  \t0.475913\t0  \t0.354132\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "210\t273  \t0.480189\t0  \t0.36936 \t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "211\t305  \t0.478022\t0  \t0.366792\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "212\t315  \t0.475527\t0  \t0.353698\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "213\t335  \t0.466707\t0  \t0.325755\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "214\t303  \t0.473707\t0  \t0.34586 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "215\t304  \t0.471079\t0  \t0.337788\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "216\t319  \t0.474408\t0  \t0.347784\t1       \n",
            "1.0 1.0 0.003125\n",
            "217\t307  \t0.475986\t0  \t0.352779\t1       \n",
            "0.982607368881035 0.9937888198757764 0.0030515756797547667\n",
            "218\t305  \t0.472199\t0  \t0.349939\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "219\t310  \t0.474668\t0  \t0.350982\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "220\t299  \t0.477776\t0  \t0.359824\t1       \n",
            "0.9913418283769 0.9968944099378882 0.0030787013303630434\n",
            "221\t289  \t0.47721 \t0  \t0.362722\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "222\t296  \t0.473482\t0  \t0.346643\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "223\t312  \t0.472303\t0  \t0.341799\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "224\t295  \t0.478906\t0  \t0.362834\t1       \n",
            "0.982607368881035 0.9937888198757764 0.003061082146046838\n",
            "225\t279  \t0.478858\t0  \t0.373322\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "226\t303  \t0.474578\t0  \t0.350471\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "227\t302  \t0.471777\t0  \t0.340941\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "228\t310  \t0.473014\t0  \t0.343913\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "229\t309  \t0.471651\t0  \t0.339948\t1       \n",
            "0.9649012813540153 0.9875776397515528 0.0030247689070658787\n",
            "230\t276  \t0.471821\t0  \t0.357955\t1       \n",
            "0.9789450103725609 0.9658385093167702 0.003037228016719403\n",
            "231\t301  \t0.466849\t0  \t0.345823\t1       \n",
            "0.9672673160021797 0.9472049689440993 0.002941630338335712\n",
            "232\t317  \t0.456538\t0  \t0.326124\t1       \n",
            "0.9913418283769 0.9968944099378882 0.003088292300239564\n",
            "233\t278  \t0.467608\t0  \t0.343351\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "234\t299  \t0.473478\t0  \t0.35004 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "235\t270  \t0.478243\t0  \t0.364014\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "236\t292  \t0.475004\t0  \t0.351278\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "237\t285  \t0.47721 \t0  \t0.358181\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "238\t308  \t0.472914\t0  \t0.344055\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "239\t324  \t0.469323\t0  \t0.332796\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "240\t299  \t0.478275\t0  \t0.36093 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "241\t271  \t0.475467\t0  \t0.352068\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "242\t308  \t0.47448 \t0  \t0.34913 \t1       \n",
            "0.9737945687202026 0.9906832298136646 0.003024206735155909\n",
            "243\t274  \t0.471275\t0  \t0.350853\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "244\t266  \t0.479411\t0  \t0.371302\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "245\t299  \t0.471599\t0  \t0.341348\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "246\t299  \t0.470716\t0  \t0.338308\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "247\t265  \t0.473875\t0  \t0.348528\t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "248\t318  \t0.470398\t0  \t0.33727 \t1       \n",
            "1.0 1.0 0.003105590062111801\n",
            "249\t314  \t0.468398\t0  \t0.331097\t1       \n",
            "Best individual :  cos(sub(exp(ARG64), sin(ARG106))) (1.0, 0.014925373134328358)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc-wqAxoT45D"
      },
      "source": [
        "**Prediction task**\n",
        "\n",
        "1.   Create new data from the list of fittest individual (fittest features) for both training and testing data.\n",
        "2.   Fit the svm with transformed training data\n",
        "3.   Predict the transformed testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRyeLuWSrGwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41942925-722a-4f6e-a585-f4d9643e9eb1"
      },
      "source": [
        "#1. Evaluate the expression for training set\n",
        "list_train_vecs = []\n",
        "max_value = max([individual.fitness.values[0] for individual in hof])\n",
        "\n",
        "for individual in hof:\n",
        "  if individual.fitness.values[0] == max_value:\n",
        "      func = toolbox.compile(expr=individual)\n",
        "      vec = []\n",
        "      for x_train in X_train: #Iterate every vector x (row) in data (matrix) X\n",
        "        try:\n",
        "          val = func(*x_train)\n",
        "          vec.append(val)\n",
        "        except:\n",
        "          vec.append(0)\n",
        "      list_train_vecs.append(vec)\n",
        "\n",
        "#2. Evaluate the expression for testing set\n",
        "list_test_vecs = []\n",
        "for individual in hof:\n",
        "  if individual.fitness.values[0] == max_value:\n",
        "      func = toolbox.compile(expr=individual)\n",
        "      vec = []\n",
        "      for x_test in X_test: #Iterate every vector x (row) in data (matrix) X\n",
        "        try:\n",
        "          val = func(*x_test)\n",
        "          vec.append(val)\n",
        "        except:\n",
        "          vec.append(0)\n",
        "      list_test_vecs.append(vec)\n",
        "\n",
        "#3. Convert list_vecs to numpy array\n",
        "X_train_new = np.array(list_train_vecs).T   #Need to refactor X_train g\n",
        "X_train_new = np.nan_to_num(X_train_new, copy=True, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_train_new = np.hstack((X_train, X_train_new))\n",
        "\n",
        "X_test_new = np.array(list_test_vecs).T   #Need to refactor X_test g\n",
        "X_test_new = np.nan_to_num(X_test_new, copy=True, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_test_new = np.hstack((X_test, X_test_new))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVGPM V2 - Accuracy-Score:  0.7482014388489209\n",
            "SVGPM V2 - F1-Score:  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_CnWmUscRHR",
        "outputId": "4c1e2c8e-3b04-45b1-fac8-1e6113344f59"
      },
      "source": [
        "#Additional evaluation\n",
        "#1. Fit the SVM\n",
        "list_accuracy_result = []\n",
        "list_f1_result = []\n",
        "for c in range(-5,6):\n",
        "  for g in range(-4,6):\n",
        "    clf_svc = SVC(C=2**c, gamma=2**g, class_weight=class_weight)\n",
        "    clf_svc.fit(X_train, y_train)\n",
        "    y_pred = clf_svc.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    list_accuracy_result.append(accuracy)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    list_f1_result.append(f1)\n",
        "\n",
        "print(\"SVM - Highest Accuracy-Score: \", max(list_accuracy_result))\n",
        "print(\"SVM - Highest F1-Score: \", max(list_f1_result))\n",
        "\n",
        "\n",
        "#2. Fit the SVM (SVGPM)\n",
        "list_accuracy_result = []\n",
        "list_f1_result = []\n",
        "for c in range(-5,6):\n",
        "  for g in range(-4,6):\n",
        "    clf_svc = SVC(C=2**c, gamma=2**g, class_weight=class_weight)\n",
        "    clf_svc.fit(X_train_new, y_train)\n",
        "    y_pred = clf_svc.predict(X_test_new)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    list_accuracy_result.append(accuracy)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    list_f1_result.append(f1)\n",
        "\n",
        "print(\"SVGPM V2 - Highest Accuracy-Score: \", max(list_accuracy_result))\n",
        "print(\"SVGPM V2 - Highest F1-Score: \", max(list_f1_result))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM - Highest Accuracy-Score:  0.7482014388489209\n",
            "SVM - Highest F1-Score:  0.0\n",
            "SVGPM V2 - Highest Accuracy-Score:  0.7482014388489209\n",
            "SVGPM V2 - Highest F1-Score:  0.40229885057471265\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}