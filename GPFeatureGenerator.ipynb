{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPFeatureGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnsbCDoCJNC4j1clVaCg8Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spozi/gpu-svgpm/blob/main/GPFeatureGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_ZEI1ZknHnT",
        "outputId": "f1573596-c632-44fe-b4c1-d2cdc6b66e71"
      },
      "source": [
        "!pip install -U deap imbalanced-learn scikit-learn-intelex"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: scikit-learn-intelex in /usr/local/lib/python3.7/dist-packages (2021.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (0.24.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn) (2.2.0)\n",
            "Requirement already satisfied: daal4py==2021.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-intelex) (2021.3.0)\n",
            "Requirement already satisfied: daal==2021.3.0 in /usr/local/lib/python3.7/dist-packages (from daal4py==2021.3.0->scikit-learn-intelex) (2021.3.0)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from daal==2021.3.0->daal4py==2021.3.0->scikit-learn-intelex) (2021.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irgcpLpFBF-3",
        "outputId": "a154105e-de49-4883-bf05-13454e3d6d08"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import site\n",
        "sys.path.append(os.path.join(os.path.dirname(site.getsitepackages()[0]), \"site-packages\"))\n",
        "\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASNSiD1zsUJ8"
      },
      "source": [
        "#@title SVGPM Configuration\n",
        "#@markdown ---\n",
        "#@markdown ### Enter a file path:\n",
        "train_file_path = \"/content/Earthquakes_train.csv\" #@param {type:\"string\"}\n",
        "test_file_path = \"/content/Earthquakes_test.csv\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ### Enter SVGPM Parameters:\n",
        "population_size = 500 #@param {type:\"slider\", min:0, max:1000, step:2}\n",
        "number_of_generation = 150 #@param {type:\"slider\", min:0, max:1000, step:2}\n",
        "#@markdown ---"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjaiCtAhnPHP"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#Train and test file\n",
        "train_file = train_file_path\n",
        "test_file = test_file_path\n",
        "\n",
        "train_data = np.loadtxt(train_file, delimiter=\",\", skiprows=1)\n",
        "test_data = np.loadtxt(test_file, delimiter=\",\", skiprows=1)\n",
        "\n",
        "X_train = train_data[:, 1:]\n",
        "X_test = test_data[:, 1:]\n",
        "\n",
        "#Scale each feature to 0 and 1\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#y_train\n",
        "y_train = train_data[:, 0].astype(int)\n",
        "y_test = test_data[:, 0].astype(int)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkDFiNBCDHCD",
        "outputId": "9d6f13ee-31ad-4a06-d2c8-777de9217fbc"
      },
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(322, 512) (139, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPTXrbRK9CbG"
      },
      "source": [
        "#Specify X_train, X_test, y_train, y_test here\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "# X_train.shape"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n4G13-SRMp2"
      },
      "source": [
        "Version 2 GP Feature Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UpoPcmQMMda"
      },
      "source": [
        "import random\n",
        "import operator\n",
        "import math\n",
        "import statistics\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from deap import algorithms\n",
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "from deap import gp\n",
        "\n",
        "# Define new functions\n",
        "def protectedDiv(left, right):\n",
        "    try:\n",
        "        return left / right\n",
        "    except ZeroDivisionError:\n",
        "        return 1\n",
        "\n",
        "nFeatures = X_train.data.shape[1]\n",
        "pset = gp.PrimitiveSet(\"MAIN\", nFeatures) \n",
        "pset.addPrimitive(operator.add, 2)\n",
        "pset.addPrimitive(operator.sub, 2)\n",
        "pset.addPrimitive(operator.mul, 2)\n",
        "pset.addPrimitive(protectedDiv, 2)\n",
        "pset.addPrimitive(operator.neg, 1)\n",
        "pset.addPrimitive(math.erfc, 1)\n",
        "pset.addPrimitive(math.erf, 1)\n",
        "pset.addPrimitive(math.exp, 1)\n",
        "pset.addPrimitive(math.gamma, 1)\n",
        "pset.addPrimitive(math.sqrt, 1)\n",
        "pset.addPrimitive(math.cos, 1)\n",
        "pset.addPrimitive(math.sin, 1)\n",
        "pset.addEphemeralConstant(\"rand\", lambda: round(random.uniform(0.1, 1.0), 10))\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Tree\", gp.PrimitiveTree)\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"main_expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=5)\n",
        "toolbox.register('MAIN', tools.initIterate, creator.Tree, toolbox.main_expr)\n",
        "\n",
        "func_cycle = [toolbox.MAIN]\n",
        "\n",
        "toolbox.register(\"individual\", tools.initCycle, creator.Individual, func_cycle)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71GGjz4mQ9SS"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.feature_selection import SelectKBest, chi2, SelectPercentile\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from time import time\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def evalSymbReg(score):\n",
        "  return score,\n",
        "\n",
        "def evalSymbRegPop(population):\n",
        "  # Evaluate each individual in population\n",
        "  #1. Compute the expression of every individual\n",
        "  list_vecs = []\n",
        "  # start = time()\n",
        "  for individual in population:\n",
        "    #The following code should be optimized/vectorized\n",
        "    #Evaluating expression on each vector\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    vec = []\n",
        "    for x in X_train: #Iterate every vector x (row) in data (matrix) X\n",
        "      try:\n",
        "        val = func(*x)\n",
        "        vec.append(val)\n",
        "      except:\n",
        "        vec.append(0)\n",
        "    list_vecs.append(vec)\n",
        "  end = time()\n",
        "  # expression_evaluation_time = end - start\n",
        "\n",
        "  #2. Convert list_vecs to numpy array\n",
        "  evaluated_X = np.array(list_vecs).T\n",
        "  evaluated_X = np.float32(evaluated_X)\n",
        "  evaluated_X = np.nan_to_num(evaluated_X, copy=True, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "  #3. Individual (feature) selection\n",
        "  # https://scikit-learn.org/stable/modules/feature_selection.html#feature-selection-using-selectfrommodel\n",
        "\n",
        "  # start = time()\n",
        "  clf = ExtraTreesClassifier(n_estimators=50)\n",
        "  clf = clf.fit(evaluated_X, y_train)\n",
        "\n",
        "\n",
        "  #4. Extract features that at top threshold (get the 75 percentile)\n",
        "  q1 = np.percentile(clf.feature_importances_, 50)  #Get the top 75 percentile features\n",
        "  features = [True if val >= q1 else False for val in clf.feature_importances_.tolist()] #Get the features indices\n",
        "  X_train_new = evaluated_X[:, features]  #Extract the required data\n",
        "  # end = time()\n",
        "  # feature_evaluation_time = end - start\n",
        "\n",
        "  #5. Merge X_train with X_train_new row-wise\n",
        "  X_train_new = np.hstack((X_train, X_train_new))\n",
        "\n",
        "  #6. Use svc to get total nSV\n",
        "  # start = time()\n",
        "  clf_svc = SVC(C=1, kernel='linear')     #Smaller C value will increase the margin size of the hyperplane. The new features should be generate such that it has very high linear seperability\n",
        "  clf_svc.fit(X_train_new, y_train)       #98% of runtime is at here\n",
        "  # end = time()\n",
        "  # svm_training_time = end - start\n",
        "\n",
        "  # print(\"Expression evaluation: %.4f, Feature evaluation: %.4f, SVM training: %.4f\" % (expression_evaluation_time, feature_evaluation_time, svm_training_time))\n",
        "\n",
        "  y_pred = clf_svc.predict(X_train_new)\n",
        "\n",
        "  #7. Compute the score\n",
        "  nSV = clf_svc.support_vectors_.shape[0]\n",
        "  tn, fp, fn, tp = confusion_matrix(y_train, y_pred).ravel()\n",
        "  f1 = f1_score(y_train, y_pred)\n",
        "  accuracy = accuracy_score(y_train, y_pred)\n",
        "  specificity = tp / (tp + fn)\n",
        "  sensititivy = tn / (tn + fp)\n",
        "  gmean = math.sqrt(specificity * sensititivy)\n",
        "  fitness = min(gmean,accuracy)/nSV\n",
        "\n",
        "  #8. Output the fitness value\n",
        "  ind_pop_fitness = []\n",
        "  for f in features:\n",
        "    if f is True:\n",
        "      ind_pop_fitness.append(fitness) #If the feature is in the tree, set the fitness value to fitness\n",
        "    else:\n",
        "      ind_pop_fitness.append(0)       #If the feature is in the tree, set the fitness value to 0\n",
        "  \n",
        "  return ind_pop_fitness\n",
        "\n",
        "psets = [pset]\n",
        "toolbox.register(\"compile\", gp.compileADF, psets=psets)\n",
        "toolbox.register('evaluate', evalSymbReg)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)\n",
        "toolbox.register('mate', gp.cxOnePoint)\n",
        "toolbox.register(\"expr\", gp.genFull, min_=1, max_=2)\n",
        "toolbox.register('mutate', gp.mutUniform, expr=toolbox.expr)\n",
        "\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=80))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=80))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_7HXCBEMQmU",
        "outputId": "413f7c23-6f2f-47dd-da35-21e95e3baeb5"
      },
      "source": [
        "def main():\n",
        "  random.seed(1024)\n",
        "  ind = toolbox.individual()\n",
        "  \n",
        "  pop = toolbox.population(n=population_size)\n",
        "  hof = tools.HallOfFame(population_size)\n",
        "  stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "  stats.register(\"avg\", np.mean)\n",
        "  stats.register(\"std\", np.std)\n",
        "  stats.register(\"min\", np.min)\n",
        "  stats.register(\"max\", np.max)\n",
        "\n",
        "  logbook = tools.Logbook()\n",
        "  logbook.header = \"gen\", \"evals\", \"std\", \"min\", \"avg\", \"max\"\n",
        "\n",
        "  CXPB, MUTPB, NGEN = 0.5, 0.2, number_of_generation\n",
        "\n",
        "  # # Evaluate the entire population\n",
        "#################################This is for adhoc code draft##########################################################################\n",
        "  #0. Test each indvidiual in population\n",
        "\n",
        "  # list_vecs = []\n",
        "  # for ind in pop:\n",
        "  #   func = toolbox.compile(expr=ind)\n",
        "\n",
        "  #   #The following code should be optimized\n",
        "  #   #Evaluating expression on each vector\n",
        "  #   func = toolbox.compile(expr=ind)\n",
        "  #   vec = []\n",
        "  #   for x in X: #Iterate every vector x (row) in data (matrix) X\n",
        "  #     val = func(*x)\n",
        "  #     # try:\n",
        "  #     #   val = func(*x)\n",
        "  #     # except:\n",
        "  #     #   print(x, [str(eq) for eq in ind])\n",
        "  #       # print(ind[0])\n",
        "  #     # print(val)\n",
        "  #     vec.append(val)\n",
        "  #   list_vecs.append(vec)\n",
        "\n",
        "  # #2. Convert list_vecs to numpy array\n",
        "  # evaluated_X = np.array(list_vecs).T\n",
        "  # evaluated_X = np.nan_to_num(evaluated_X, copy=True, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "  # clf = ExtraTreesClassifier(n_estimators=50)\n",
        "  # clf = clf.fit(evaluated_X, y)\n",
        "\n",
        "  # #4. Extract features that at top threshold (get the 75 percentile)\n",
        "  # q1 = np.percentile(clf.feature_importances_, 75)\n",
        "  # print( clf.feature_importances_.tolist())\n",
        "  # features = [True if val >= q1 else False for val in clf.feature_importances_.tolist()]\n",
        "  # print(len(features), evaluated_X.shape)\n",
        "  # new_X = evaluated_X[:, features]\n",
        "  # print(new_X.shape)\n",
        "  # 2/0\n",
        "\n",
        "  # #4. \n",
        "\n",
        "\n",
        "\n",
        "###########################################################################################################\n",
        "  #1. Compute the metric on the set of individuals\n",
        "  ind_pop_fitness = evalSymbRegPop(pop)\n",
        "\n",
        "  #2. Then, determine the best individual using toolbox\n",
        "  for ind, fitness in zip(pop, ind_pop_fitness):\n",
        "    ind.fitness.values = toolbox.evaluate(fitness)\n",
        "\n",
        "  hof.update(pop)\n",
        "  record = stats.compile(pop)\n",
        "  logbook.record(gen=0, evals=len(pop), **record)\n",
        "  print(logbook.stream)\n",
        "\n",
        "  for g in range(1, NGEN):\n",
        "    # Select the offspring\n",
        "    offspring = toolbox.select(pop, len(pop))\n",
        "    # Clone the offspring\n",
        "    offspring = [toolbox.clone(ind) for ind in offspring]\n",
        "\n",
        "    # Apply crossover and mutation\n",
        "    for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
        "        for tree1, tree2 in zip(ind1, ind2):\n",
        "            if random.random() < CXPB:\n",
        "                toolbox.mate(tree1, tree2)\n",
        "                del ind1.fitness.values\n",
        "                del ind2.fitness.values\n",
        "\n",
        "    for ind in offspring:\n",
        "        for tree, pset in zip(ind, psets):\n",
        "            if random.random() < MUTPB:\n",
        "                toolbox.mutate(individual=tree, pset=pset)\n",
        "                del ind.fitness.values\n",
        "                        \n",
        "    # Evaluate the individuals with an invalid fitness\n",
        "    invalids = [ind for ind in offspring if not ind.fitness.valid]\n",
        "\n",
        "    #1. Compute the metric on the set of individuals\n",
        "    ind_pop_invalid_fitness = evalSymbRegPop(invalids)\n",
        "\n",
        "    #2. Then, determine the best individual using toolbox\n",
        "    for ind, fitness in zip(invalids, ind_pop_invalid_fitness):\n",
        "      ind.fitness.values = toolbox.evaluate(fitness)\n",
        "            \n",
        "    # Replacement of the population by the offspring\n",
        "    pop = offspring\n",
        "    hof.update(pop)\n",
        "    record = stats.compile(pop)\n",
        "    logbook.record(gen=g, evals=len(invalids), **record)\n",
        "    print(logbook.stream)\n",
        "  \n",
        "  print('Best individual : ', hof[0][0], hof[0].fitness)\n",
        "  return pop, stats, hof\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pop, stats, hof = main()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expression evaluation: 9.1451, Feature evaluation: 0.0985, SVM training: 82.5695\n",
            "gen\tevals\tstd\tmin\tavg\tmax\n",
            "0  \t500  \t0  \t0  \t0  \t0  \n",
            "Expression evaluation: 5.2604, Feature evaluation: 0.0919, SVM training: 7.5600\n",
            "1  \t282  \t0.00144097\t0  \t0.000903061\t0.00320235\n",
            "Expression evaluation: 5.7773, Feature evaluation: 0.0913, SVM training: 0.0494\n",
            "2  \t317  \t0.00135578\t0  \t0.000749349\t0.00320235\n",
            "Expression evaluation: 5.2892, Feature evaluation: 0.0964, SVM training: 149.1339\n",
            "3  \t290  \t0.0021988 \t0  \t0.00218006 \t0.00499975\n",
            "Expression evaluation: 5.0723, Feature evaluation: 0.0909, SVM training: 36.4805\n",
            "4  \t280  \t0.00261084\t0  \t0.0035417  \t0.00625269\n",
            "Expression evaluation: 4.9321, Feature evaluation: 0.0939, SVM training: 4.7457\n",
            "5  \t270  \t0.00244795\t0  \t0.00338851 \t0.00625269\n",
            "Expression evaluation: 5.4541, Feature evaluation: 0.0958, SVM training: 150.6980\n",
            "6  \t297  \t0.00244649\t0  \t0.00296964 \t0.00625269\n",
            "Expression evaluation: 5.0811, Feature evaluation: 0.0906, SVM training: 175.2818\n",
            "7  \t280  \t0.00240267\t0  \t0.00275073 \t0.00625269\n",
            "Expression evaluation: 5.6950, Feature evaluation: 0.0911, SVM training: 153.8457\n",
            "8  \t312  \t0.00229704\t0  \t0.00253797 \t0.00625269\n",
            "Expression evaluation: 5.7994, Feature evaluation: 0.0924, SVM training: 290.7268\n",
            "9  \t315  \t0.0023336 \t0  \t0.0022248  \t0.00625269\n",
            "Expression evaluation: 5.3218, Feature evaluation: 0.1027, SVM training: 7.4468\n",
            "10 \t289  \t0.0022355 \t0  \t0.00252858 \t0.00625269\n",
            "Expression evaluation: 5.7506, Feature evaluation: 0.0968, SVM training: 104.3475\n",
            "11 \t316  \t0.00220734\t0  \t0.00240123 \t0.00625269\n",
            "Expression evaluation: 5.3088, Feature evaluation: 0.0969, SVM training: 14.9609\n",
            "12 \t291  \t0.00240708\t0  \t0.00172288 \t0.00625269\n",
            "Expression evaluation: 6.0575, Feature evaluation: 0.0992, SVM training: 151.8034\n",
            "13 \t334  \t0.00228523\t0  \t0.00249573 \t0.00625269\n",
            "Expression evaluation: 5.4076, Feature evaluation: 0.0941, SVM training: 298.0881\n",
            "14 \t299  \t0.00239568\t0  \t0.00171258 \t0.00625269\n",
            "Expression evaluation: 5.4608, Feature evaluation: 0.0944, SVM training: 16.6957\n",
            "15 \t300  \t0.00272993\t0  \t0.00321046 \t0.00625269\n",
            "Expression evaluation: 5.5883, Feature evaluation: 0.0981, SVM training: 144.5011\n",
            "16 \t308  \t0.00256215\t0  \t0.00246829 \t0.00625269\n",
            "Expression evaluation: 5.2601, Feature evaluation: 0.0981, SVM training: 7.3660\n",
            "17 \t289  \t0.00246191\t0  \t0.0021962  \t0.00625269\n",
            "Expression evaluation: 5.5888, Feature evaluation: 0.1116, SVM training: 0.0533\n",
            "18 \t309  \t0.00251141\t0  \t0.00301072 \t0.00625269\n",
            "Expression evaluation: 6.1842, Feature evaluation: 0.0954, SVM training: 202.2094\n",
            "19 \t341  \t0.00508217\t0  \t0.00576293 \t0.0121083 \n",
            "Expression evaluation: 5.8600, Feature evaluation: 0.0965, SVM training: 154.8744\n",
            "20 \t321  \t0.00474942\t0  \t0.00495777 \t0.0121083 \n",
            "Expression evaluation: 5.5946, Feature evaluation: 0.0943, SVM training: 134.5466\n",
            "21 \t307  \t0.00489574\t0  \t0.00357112 \t0.0121083 \n",
            "Expression evaluation: 5.6692, Feature evaluation: 0.0909, SVM training: 105.0158\n",
            "22 \t313  \t0.00462979\t0  \t0.00505976 \t0.0121083 \n",
            "Expression evaluation: 5.5119, Feature evaluation: 0.1811, SVM training: 4.4054\n",
            "23 \t305  \t0.00464563\t0  \t0.00429442 \t0.0121083 \n",
            "Expression evaluation: 5.4792, Feature evaluation: 0.0933, SVM training: 162.3979\n",
            "24 \t297  \t0.00461459\t0  \t0.00371387 \t0.0121083 \n",
            "Expression evaluation: 5.6633, Feature evaluation: 0.0946, SVM training: 164.1064\n",
            "25 \t308  \t0.00444065\t0  \t0.00458367 \t0.0121083 \n",
            "Expression evaluation: 5.1001, Feature evaluation: 0.1020, SVM training: 116.3709\n",
            "26 \t286  \t0.00480591\t0  \t0.00347575 \t0.0121083 \n",
            "Expression evaluation: 5.2700, Feature evaluation: 0.0937, SVM training: 151.8110\n",
            "27 \t291  \t0.00503135\t0  \t0.00323577 \t0.0121083 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f509894a260a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mpop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-f509894a260a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m#1. Compute the metric on the set of individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mind_pop_invalid_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalSymbRegPop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m#2. Then, determine the best individual using toolbox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-fbb91ea6059a>\u001b[0m in \u001b[0;36mevalSymbRegPop\u001b[0;34m(population)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mclf_svc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Smaller C value will increase the margin size of the hyperplane. The new features should be generate such that it has very high linear seperability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0mclf_svc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0msvm_training_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearnex/svm/svc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'poly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sklearn.svm.SVC.fit: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mget_patch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"onedal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onedal_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sklearn.svm.SVC.fit: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mget_patch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sklearn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearnex/svm/svc.py\u001b[0m in \u001b[0;36m_onedal_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onedal_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monedal_SVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0monedal_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onedal_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'balanced'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/onedal/svm/svm.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyClassificationSvmTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/onedal/svm/svm.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/site-packages/onedal/svm/svm.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, Computer)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mc_svm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_onedal_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mc_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc-wqAxoT45D"
      },
      "source": [
        "**Prediction task**\n",
        "\n",
        "1.   Create new data from the list of fittest individual (fittest features) for both training and testing data.\n",
        "2.   Fit the svm with transformed training data\n",
        "3.   Predict the transformed testing data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRyeLuWSrGwr"
      },
      "source": [
        "#1. Evaluate the expression for training set\n",
        "list_train_vecs = []\n",
        "for individual in hof:\n",
        "  if individual.fitness.values[0] > 0:\n",
        "      func = toolbox.compile(expr=individual)\n",
        "      vec = []\n",
        "      for x_train in X_train: #Iterate every vector x (row) in data (matrix) X\n",
        "        try:\n",
        "          val = func(*x_train)\n",
        "          vec.append(val)\n",
        "        except:\n",
        "          vec.append(0)\n",
        "      list_train_vecs.append(vec)\n",
        "\n",
        "#2. Evaluate the expression for testing set\n",
        "list_test_vecs = []\n",
        "for individual in hof:\n",
        "  if individual.fitness.values[0] > 0:\n",
        "      func = toolbox.compile(expr=individual)\n",
        "      vec = []\n",
        "      for x_test in X_test: #Iterate every vector x (row) in data (matrix) X\n",
        "        try:\n",
        "          val = func(*x_test)\n",
        "          vec.append(val)\n",
        "        except:\n",
        "          vec.append(0)\n",
        "      list_test_vecs.append(vec)\n",
        "\n",
        "#2. Convert list_vecs to numpy array\n",
        "X_train_new = np.array(list_train_vecs).T   #Need to refactor X_train g\n",
        "X_train_new = np.nan_to_num(X_train_new, copy=True, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_train_new = np.hstack((X_train, X_train_new))\n",
        "\n",
        "X_test_new = np.array(list_test_vecs).T   #Need to refactor X_test g\n",
        "X_test_new = np.nan_to_num(X_test_new, copy=True, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "X_test_new = np.hstack((X_test, X_test_new))\n",
        "\n",
        "\n",
        "#3. Fit the SVM\n",
        "list_accuracy_result = []\n",
        "list_f1_result = []\n",
        "for c in range(-5,6):\n",
        "  for g in range(-4,6):\n",
        "    clf_svc = SVC(C=2**c, gamma=2**g)\n",
        "    clf_svc.fit(X_train, y_train)\n",
        "    y_pred = clf_svc.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    list_accuracy_result.append(accuracy)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    list_f1_result.append(f1)\n",
        "\n",
        "print(\"SVM - Highest Accuracy-Score: \", max(list_accuracy_result))\n",
        "print(\"SVM - Highest F1-Score: \", max(list_f1_result))\n",
        "\n",
        "\n",
        "#4. Fit the SVM (SVGPM)\n",
        "list_accuracy_result = []\n",
        "list_f1_result = []\n",
        "for c in range(-5,6):\n",
        "  for g in range(-4,6):\n",
        "    clf_svc = SVC(C=2**c, gamma=2**g)\n",
        "    clf_svc.fit(X_train_new, y_train)\n",
        "    y_pred = clf_svc.predict(X_test_new)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    list_accuracy_result.append(accuracy)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    list_f1_result.append(f1)\n",
        "\n",
        "print(\"SVGPM V2 - Highest Accuracy-Score: \", max(list_accuracy_result))\n",
        "print(\"SVGPM V2 - Highest F1-Score: \", max(list_f1_result))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}